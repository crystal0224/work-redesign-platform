import Anthropic from '@anthropic-ai/sdk';
import { Task } from '../types/workshop';
import { logger } from '../utils/logger';
import { getAICache } from './ai-cache.service';

export class ClaudeService {
  private anthropic: Anthropic;

  constructor() {
    if (!process.env.ANTHROPIC_API_KEY) {
      throw new Error('ANTHROPIC_API_KEY is required');
    }

    this.anthropic = new Anthropic({
      apiKey: process.env.ANTHROPIC_API_KEY,
    });
  }

  async analyzeTasks(documentText: string, domains: string[]): Promise<Task[]> {
    logger.info('ğŸ¤– Starting Claude AI task analysis');

    const systemPrompt = `ë‹¹ì‹ ì€ ì—…ë¬´ ì¬ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ë°˜ë³µì ì¸ ì—…ë¬´ë¥¼ ì¶”ì¶œí•˜ê³  ìë™í™” ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.

ì—…ë¬´ ì˜ì—­: ${domains.join(', ')}

ê° ì—…ë¬´ëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
- title: ì—…ë¬´ëª… (ê°„ê²°í•˜ê²Œ)
- description: ì—…ë¬´ ì„¤ëª…
- timeSpent: ì†Œìš” ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„, ìˆ«ì)
- frequency: ë¹ˆë„ (daily/weekly/monthly)
- automation: ìë™í™” ê°€ëŠ¥ì„± (high/medium/low)
- automationMethod: ìë™í™” ë°©ë²• ì œì•ˆ (êµ¬ì²´ì ìœ¼ë¡œ)
- category: ì—…ë¬´ ì˜ì—­ (ìœ„ ë„ë©”ì¸ ì¤‘ í•˜ë‚˜)

JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.`;

    const userMessage = `ë‹¤ìŒ ë¬¸ì„œì—ì„œ ë°˜ë³µì ì¸ ì—…ë¬´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

${documentText.substring(0, 8000)}`;

    try {
      // ğŸ’° Check cache first
      const aiCache = getAICache();
      const cacheKey = `${systemPrompt}\n${userMessage}`;
      const cachedResult = await aiCache.getCachedResponse(cacheKey, { domains });

      if (cachedResult) {
        const tasks = JSON.parse(cachedResult);
        logger.info(`ğŸ’° Cache HIT! ${tasks.length} tasks retrieved from cache - API call saved!`);
        return tasks;
      }

      const response = await this.anthropic.messages.create({
        model: 'claude-3-5-sonnet-20241022',
        max_tokens: 4000,
        temperature: 0.3,
        system: systemPrompt,
        messages: [{
          role: 'user',
          content: userMessage
        }]
      });

      const textContent = response.content[0];
      if (textContent.type !== 'text') {
        throw new Error('Unexpected response type from Claude');
      }

      // JSON ì¶”ì¶œ
      const jsonMatch = textContent.text.match(/\[[\s\S]*\]/);
      if (!jsonMatch) {
        logger.error('No JSON format found in Claude response:', textContent.text);
        return [];
      }

      const tasks = JSON.parse(jsonMatch[0]);
      logger.info(`âœ… ${tasks.length} tasks extracted by Claude`);

      // ğŸ’° Store in cache for future requests
      await aiCache.setCachedResponse(cacheKey, { domains }, JSON.stringify(tasks));
      logger.info('ğŸ’° Response cached for future use');

      return tasks;

    } catch (error) {
      logger.error('Claude API error:', error);
      throw error;
    }
  }

  async generateAIPrompt(task: Task): Promise<string> {
    const systemPrompt = `ë‹¹ì‹ ì€ AI í”„ë¡¬í”„íŠ¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì—…ë¬´ë¥¼ ìë™í™”í•˜ê¸° ìœ„í•œ Claude/ChatGPTìš© í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
í”„ë¡¬í”„íŠ¸ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.`;

    const userMessage = `ë‹¤ìŒ ì—…ë¬´ë¥¼ ìœ„í•œ AI í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì—…ë¬´ëª…: ${task.title}
ì„¤ëª…: ${task.description}
ìë™í™” ë°©ë²•: ${task.automationMethod}
ì†Œìš” ì‹œê°„: ${task.timeSpent}ì‹œê°„/${task.frequency}
ì¹´í…Œê³ ë¦¬: ${task.category}

í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ì—­í•  ì •ì˜
2. êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œ
3. ì…ë ¥ í˜•ì‹ ì„¤ëª…
4. ì¶œë ¥ í˜•ì‹ ì„¤ëª…
5. ì˜ˆì‹œ (í•„ìš”ì‹œ)`;

    try {
      // ğŸ’° Check cache first
      const aiCache = getAICache();
      const cacheKey = `${systemPrompt}\n${userMessage}`;
      const cachedResult = await aiCache.getCachedResponse(cacheKey, { taskId: task.id });

      if (cachedResult) {
        logger.info(`ğŸ’° Cache HIT! AI prompt retrieved from cache - API call saved!`);
        return cachedResult;
      }

      const response = await this.anthropic.messages.create({
        model: 'claude-3-5-sonnet-20241022',
        max_tokens: 2000,
        temperature: 0.5,
        system: systemPrompt,
        messages: [{
          role: 'user',
          content: userMessage
        }]
      });

      const textContent = response.content[0];
      if (textContent.type !== 'text') {
        throw new Error('Unexpected response type from Claude');
      }

      // ğŸ’° Store in cache for future requests
      await aiCache.setCachedResponse(cacheKey, { taskId: task.id }, textContent.text);
      logger.info('ğŸ’° AI prompt cached for future use');

      return textContent.text;

    } catch (error) {
      logger.error('Claude prompt generation error:', error);
      throw error;
    }
  }

  async generatePythonScript(task: Task): Promise<string> {
    const systemPrompt = `ë‹¹ì‹ ì€ Python ê°œë°œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì—…ë¬´ë¥¼ ìë™í™”í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  ì£¼ì„ì´ ì˜ ë‹¬ë ¤ìˆì–´ì•¼ í•©ë‹ˆë‹¤.`;

    const userMessage = `ë‹¤ìŒ ì—…ë¬´ë¥¼ ìë™í™”í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì—…ë¬´ëª…: ${task.title}
ì„¤ëª…: ${task.description}
ìë™í™” ë°©ë²•: ${task.automationMethod}
ë¹ˆë„: ${task.frequency}

ìš”êµ¬ì‚¬í•­:
- ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œ
- ì ì ˆí•œ ì—ëŸ¬ í•¸ë“¤ë§
- ìƒì„¸í•œ ì£¼ì„
- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
- ì„¤ì • ë³€ìˆ˜ëŠ” ìƒë‹¨ì— ì •ì˜
- main í•¨ìˆ˜ êµ¬ì¡° ì‚¬ìš©`;

    try {
      // ğŸ’° Check cache first
      const aiCache = getAICache();
      const cacheKey = `${systemPrompt}\n${userMessage}`;
      const cachedResult = await aiCache.getCachedResponse(cacheKey, { taskId: task.id });

      if (cachedResult) {
        logger.info(`ğŸ’° Cache HIT! Python script retrieved from cache - API call saved!`);
        return cachedResult;
      }

      const response = await this.anthropic.messages.create({
        model: 'claude-3-5-sonnet-20241022',
        max_tokens: 3000,
        temperature: 0.3,
        system: systemPrompt,
        messages: [{
          role: 'user',
          content: userMessage
        }]
      });

      const textContent = response.content[0];
      if (textContent.type !== 'text') {
        throw new Error('Unexpected response type from Claude');
      }

      // ğŸ’° Store in cache for future requests
      await aiCache.setCachedResponse(cacheKey, { taskId: task.id }, textContent.text);
      logger.info('ğŸ’° Python script cached for future use');

      return textContent.text;

    } catch (error) {
      logger.error('Claude Python script generation error:', error);
      throw error;
    }
  }

  async generateN8nWorkflow(task: Task): Promise<string> {
    const systemPrompt = `ë‹¹ì‹ ì€ n8n ì›Œí¬í”Œë¡œìš° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì—…ë¬´ë¥¼ ìë™í™”í•˜ëŠ” n8n ì›Œí¬í”Œë¡œìš° JSONì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì›Œí¬í”Œë¡œìš°ëŠ” ì‹¤ì œë¡œ import ê°€ëŠ¥í•œ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.`;

    const userMessage = `ë‹¤ìŒ ì—…ë¬´ë¥¼ ìë™í™”í•˜ëŠ” n8n ì›Œí¬í”Œë¡œìš°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì—…ë¬´ëª…: ${task.title}
ì„¤ëª…: ${task.description}
ìë™í™” ë°©ë²•: ${task.automationMethod}
ë¹ˆë„: ${task.frequency}

ì›Œí¬í”Œë¡œìš° ìš”êµ¬ì‚¬í•­:
- n8nì—ì„œ ë°”ë¡œ import ê°€ëŠ¥í•œ JSON í˜•ì‹
- ì ì ˆí•œ ë…¸ë“œ ì—°ê²°
- íŠ¸ë¦¬ê±° ì„¤ì • (ìŠ¤ì¼€ì¤„ëŸ¬, ì›¹í›… ë“±)
- ì—ëŸ¬ í•¸ë“¤ë§ ë…¸ë“œ í¬í•¨
- ì£¼ì„ ë…¸ë“œë¡œ ì„¤ëª… ì¶”ê°€`;

    try {
      // ğŸ’° Check cache first
      const aiCache = getAICache();
      const cacheKey = `${systemPrompt}\n${userMessage}`;
      const cachedResult = await aiCache.getCachedResponse(cacheKey, { taskId: task.id });

      if (cachedResult) {
        logger.info(`ğŸ’° Cache HIT! n8n workflow retrieved from cache - API call saved!`);
        return cachedResult;
      }

      const response = await this.anthropic.messages.create({
        model: 'claude-3-5-sonnet-20241022',
        max_tokens: 3000,
        temperature: 0.3,
        system: systemPrompt,
        messages: [{
          role: 'user',
          content: userMessage
        }]
      });

      const textContent = response.content[0];
      if (textContent.type !== 'text') {
        throw new Error('Unexpected response type from Claude');
      }

      // JSON ì¶”ì¶œ
      const jsonMatch = textContent.text.match(/```json\n([\s\S]*?)\n```/) ||
                       textContent.text.match(/\{[\s\S]*\}/);

      const result = jsonMatch ? (jsonMatch[1] || jsonMatch[0]) : textContent.text;

      // ğŸ’° Store in cache for future requests
      await aiCache.setCachedResponse(cacheKey, { taskId: task.id }, result);
      logger.info('ğŸ’° n8n workflow cached for future use');

      return result;

    } catch (error) {
      logger.error('Claude n8n workflow generation error:', error);
      throw error;
    }
  }
}